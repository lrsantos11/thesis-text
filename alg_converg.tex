%!TEX root = tese.tex


\setchapterpreamble[u]{% 
% \dictum[Thomas A.~ Edison]{``There is no substitute for hard work.''}
\dictum[Booker T.~Washington]{``Nothing ever comes to one, that is worth having, except as a result of hard work.''}
}



\chapter{Convergência  Polinomial do Método de Escolha Otimizada de Parâmetros}


\label{chap:convergence}


Conforme esclarecem \textcite{Zhang:1993gn}, do ponto de vista matemático, os conceitos de polinomialidade de um algoritmo e de taxa de convergência são incompatíveis. Enquanto a polinomialidade tem sentido apenas quando o algoritmo termina em um número finito de passos, a taxa de convergência  está definida apenas para métodos que tomam infinitos passos para convergir. Quando diz-se que um Método de Pontos Interiores é polinomial, tem-se em mente dados inteiros ou racionais e terminação finta. Por outro lado, quando diz-se que o mesmo algoritmo tem convergência linear, por exemplo, isso é feito  no sentido tradicional da análise numérica~\cite{Ortega:2000vd}.
Daí, da mesma forma que esses autores, discutiremos aqui tanto polinomialidade quanto taxa de convergência do Método de Escolha Otimizada de Parâmetros. Daí, o objetivo principal  deste capítulo é   provar  que o Algoritmo \ref{alg:optimized-choice-of-parameters} converge em uma taxa Q-linear e tem ordem polinomial de iterações.






 Para tanto,  fixaremos os parâmetros $(\mu,\sig)$. O motivo de fazermos isso é facilitarmos as contas. Neste sentido escolheremos estrategicamente  para o parâmetro  $\mu$ o valor \[\nextmu=\eta\dfrac{x^Tz}{n},
\] 
em que $\eta\in (\eta_{\min},\eta_{\max} )$, enquanto o parâmetro $\sig$ será fixado como $\nextsig =0 $. Em alguns momentos, utilizaremos apenas $\nextsig$ ao invés de $0$ pois derivaremos desigualdades importantes que vão valer para qualquer valor de $\eta$ e $\sig$. Essas escolhas  fazem com que nosso método resolva  sistemas lineares similares aos dos métodos seguidores de caminho, vistos no Capítulo~\ref{chap:mpis}. Os valores dos limitantes de $\eta$ para  estes $\nextmu$  e $\nextsig$ fixados são determinado no Lema~\ref{lemma:next-phi-delta-n4}.


 A fixação desses dois parâmetros permite as demonstrações que seguem e a consequente prova da convergência do método de maneira mais fácil. No entanto, na prática, o método  tem desempenho melhor, já que se busca, em cada iteração $k$,
o minimizador global de $\nextphi$ através da solução do problema \eqref{eq:pop-subproblem}, dado por $(\al^*,\mu^*,\sig^*)$ e portanto	$\nextphi(\al^*,\mu^*,\sig^*)\leq \nextphi(\hat{\al},\nextmu,\nextsig)$, para algum   $\hat{\al}$.

De fato, com $\mu=\nextmu$ e $\sig=\nextsig$ , vamos determinar que este $\nextal$ existe, está no intervalo $(0,1)$, cumpre com as condições da vizinhança $N_{-\infty}(\ga,\be)$, para algum $\ga$ e $\be$  e principalmente, e por último, mas não menos importante, é grande o suficiente para fazer com que a função de mérito $\nextphi$ decresça suficientemente. Vejamos como isso se dá.


% Com essas alterações, podemos rescrever o Algoritmo~\ref{alg:optimized-choice-of-parameters} como o  Algoritmo Simplificado \ref{alg:optimized-choice-of-parameters}.


A fim de pode  resolver o o problema primal-dual (\ref{eq:primal}-\ref{eq:dual}), vamos considerar válido o Pressuposto \ref{ass:interior-nonempty}, isto é, que o interior da região factível é não vazio. Além disso, vamos considerar que o \ac{PL} em questão possui ao menos uma solução ótima. 





Pelo Teorema \ref{thm:varphi}, a função de mérito para o próximo ponto   é, nas variáveis  $(\al,\mu,\sig)$,
\begin{equation*}
% \label{eq:merit-function-al-mu-sig}
{\nextphi}(\al,\mu,\sig) =  (1-\al)(\dbvec{\rho_L} +
\rhoCkb ) + \al\mu + \al(\al-\sig)\dbvec{L_{0,0}} +
\al^2\dbvec{\Lambda(\mu,\sig)} ,
\end{equation*}
em que 
\[
\dbvec{\Lambda(\mu,\sig)} = \mu^2
 \dbvec{L_{2,0}} + \mu \dbvec{L_{1,0}} + 	\mu \sig \dbvec{L_{1,1}} +
 \sig^2 \dbvec{L_{0,2}} + \sig \dbvec{L_{0,1}}.
 \]


Como vimos na Observação \ref{obs:L_02-L20},  $\dbvec{L_{2,0}} = \dbvec{L_{0,2}} = 0$. Fixando $\mu = \nextmu = \eta\frac{x^Tz}{n} = \eta\rhoCkb  $
 e $\sig = \nextsig=0$ e usando a Proposição \ref{prop:nu_k},   podemos rescrever a função de mérito para o próximo ponto, dependendo apenas de uma escolha de  $\al$ como
\begin{equation}
	\label{eq:simplified-merit-function-al}
\nextphi(\al)  = (1-\al)(\nuk \dbvec{\rho_L^{0}} +
\rhoCkb ) + \al\eta\rhoCkb  + \al^2\left(\dbvec{L_{0,0}} + \eta\rhoCkb  \dbvec{L_{1,0}}
\right) .
\end{equation}

Apenas para facilitar a notação, dada uma iteração $k$ qualquer, definimos $\nextphi = \varphi_{k+1}$ e $\varphi = \varphi_{k}$.

Seja a função auxiliar  dada por
\begin{equation}
	\label{eq:theta}
\theta(\al) =  \dfrac{\al\left[ \nuk \dbvec{\rho_L^{0}} + (1-\eta)\rhoCkb  - \al\left(\dbvec{L_{0,0}} + \eta\rhoCkb  \dbvec{L_{1,0}}
\right) \right]}{\nuk \dbvec{\rho_L^{0}} +
\rhoCkb }.
\end{equation}
Usando tal definição, deriva-se a seguinte relação entre a função de mérito atual  $\varphi$  e a da próxima iteração  $\nextphi$: 
\begin{equation}
	\label{eq:relation-phi-next-phi}
	 			{\nextphi} = (1- \theta(\al))\varphi.
\end{equation}


Como é necessário garantir que  $\nextphi  $  seja não negativa, deve-se escolher um tamanho de passo  $\al_k$, em cada iteração $k$, tal que  $\theta_k = \theta(\al_k)<1$. Além disso, se existir um escalar $\theta>0$, tal que $\theta = \liminf (\theta_k)$, isto é, se a sequência $\{\theta_k\}$ for limitada inferiormente por um valor positivo,	 então para $k$ suficientemente grande
\[
\frac{{\varphi_{k+1}}}{\varphi_{k}} < (1- \theta) < 1.
\]
e logo a sequência $\{\varphi_k\}$, gerada pelo Algoritmo \ref{alg:optimized-choice-of-parameters}, converge para zero Q-linearmente~\cite{Ortega:2000vd}.




Como vimos, para garantirmos a convergência dos pontos gerados pelo Algoritmo para uma solução ótima $(\xstar,\ystar,\zstar)$ do problema de \ac{PL}, além de ser  crucial que exista $\hat{\al}>0$  tal que,  para toda iteração $k$, tenha-se  $\al_k\in(0,\hat{\al}]$, de modo que a equação~\eqref{eq:relation-phi-next-phi} seja válida, é preciso que todo   ponto  $(\xk ,\yk,\zk)$ pertença à vizinhança $\Nset_{-\infty}(\gamma,\beta)$.

Para tanto, sejam  
\begin{equation}
	\label{eq:al-C+al-L}
\begin{cases}
	\hat{\al}_{C}^{i} = \displaystyle \max_{\al\in (0,1]} \{ \al : g_{C}^{i}(\upsilon,\nextmu,\nextsig)\geq0 \text{ para todo } 0 \leq \upsilon\leq \al  \}, & i = 1,\ldots,n,\\
	\hat{\al}_{C} = \displaystyle \min_{1\leq i \leq n} \{\hat{\al}_{C}^{i}\}, \\
	\hat{\al}_{L} = \displaystyle \max_{\al\in (0,1]} \{ \al : g_{L}(\upsilon,\nextmu,\nextsig)\geq0 \text{ para todo } 0 \leq  \upsilon\leq \al  \},
\end{cases}
\end{equation}
em que $g_{C}^{i}$ e $g_{L}$ são dadas pelas equações  \eqref{eq:g-Ci_explicit} e \eqref{eq:g-L_explicit}, já tendo sido fixados os parâmetros $\mu=\nextmu$ e $\sig=\nextsig$.


Com isso, escolheremos  $\hat\al$ que garanta decréscimo suficiente de $\nextphi$ ao mesmo em que haja a pertinência de $({x}^{k} ,{y}^{k},{z}^{k})$ à vizinhança $\Nset_{-\infty}(\gamma,\beta)$ por sujeitar $\nextphi$ tanto à  \eqref{eq:g-Ci_explicit} quanto à \eqref{eq:g-L_explicit}. Isso será feito simplesmente por escolher

\begin{equation}
	\label{eq:nex-al}
\nextal = \min\{\nextal_{C},\nextal_{L}\},
\end{equation}
em que $\nextal_{C}$ e $\nextal_{L}$ são definidos nos Lemas \ref{lemma:alC_delta-1} e  \ref{lemma:alL_delta-2}.

% -- neste caso,  em que $\mu$ e $\sig$ estão fixados --  por escolher o tamanho de passo $\nextal$ como
% \begin{equation}
% 	\label{eq:nex-al}
% \nextal = \argmax \left\{ \theta(\al): \al\in\left[0,\min\{\nextal_{C},\nextal_{L}\}\right]\right\}.
% \end{equation}
  


% De fato, a função $\theta(\al)$ é uma quadrática, e por conta disso, o problema \eqref{eq:nex-al} é resolvido por comparar os valores funcionais de $\theta(\al)$ em seus pontos críticos no interior do intervalo e o valor funcional no ponto mais a direita do intervalo.


Veremos que essa escolha garante que  o Algoritmo \ref{alg:optimized-choice-of-parameters} gere uma sequência $\{\varphi_k\}$ que decresce de maneira suficiente a cada passo, tal que $\varphi_k \to 0$, quando $k\to \infty$. Assim, o Algoritmo gera pontos $({x}^{k} ,{y}^{k},{z}^{k})$ que tem as boas propriedades da vizinhança $\Nset_{-\infty}(\gamma,\beta)$ e ainda faz com que $({x}^{k} ,{y}^{k},{z}^{k})$ convirja para  alguma solução ótima $(\xstar ,\ystar,\zstar)$ do problema primal-dual  (\ref{eq:primal}-\ref{eq:dual}).


Em seguida, fazemos a demonstração da convergência do Algoritmo proposto. A análise que segue é  baseada naquelas feitas por \textcite[cap. 6]{Wright:Primal-dual-interior-point:1997h},  \textcite{Zhang:2006ic,Zhang:1995fu}. 

% \section{Ponto Inicial}


\section{Resultados técnicos}



A fim de demonstrarmos a convergência e a complexidade do Algoritmo proposto, na presente seção provaremos alguns lemas técnicos que serão utilizados para estabelecer nossos principais resultados de convergência. 

Primeiramente, faz-se necessário  escolher  $\gamma\in(0,1)$  e $\be\geq 1$ adequados, para construir a vizinhança $\Nset_{-\infty}(\ga,\be)$. Para o primeiro parâmetro, várias escolhas são possíveis como, por exemplo, a de 
\textcite{Colombo:2008ia} que utilizam $\ga = 1/10$. Vamos escolher $\ga$ tal que  
\[
\gamma \leq  \min\left\{ \frac{\displaystyle \min_{i}(\xzero_{i} \zzero_{i} )}{(\xzero )^T\zzero /n}, \frac{1}{10}\right\},
\]
o que garante que o ponto inicial satisfaz a desigualdade~\eqref{eq:symmetric-polynomials-b}.

Com relação à $\be$,  usando um raciocínio similar, para qualquer  $\be\geq 1$, o ponto inicial sempre satisfaz \eqref{eq:symmetric-polynomials-a}. Quanto menor for $\be$, mais acelerada é a redução  das médias dos resíduos de complementaridade, dadas por $\rhoCkb $, em relação à redução da média dos resíduos de linearidade $\dbvec{\rho_L^{k}}$. Para facilitar os raciocínios, do ponto de vista teórico, vamos escolher o menor valor possível para $\beta$, isto é, $\be=1$.

Além disso a seguinte observação será  útil.


\begin{obs}
	Seja  $(\Dex,\Dey,\Dez)$ uma terna qualquer de direções. Se 
\begin{equation}
	\label{eq:Ax0-ATyz0}
	A\Dex=0 \text{ e } A^T\Dey + \Dez = 0.
\end{equation}
então
\begin{equation}
	\label{eq:xTziszero}
	\Dex^T\Dez =  - \Dex^T(A^T\Dey)  = -(A\Dex)^T\Dey = 0.
\end{equation}
\end{obs}



Em demonstrações de convergência e polinomialidade de Métodos de Pontos Interiores  infactíveis, em particular no métodos do tipo Mehrotra como o que propomos,  é  necessária a aceitação de algumas hipóteses ou condições sobre o ponto inicial e  sobre uma solução ótima. Veja por exemplo os trabalhos de \textcite{Wright:1994jd}, \textcite[cap. 6]{Wright:Primal-dual-interior-point:1997h}, \textcite{Wright:1996kj,Zhang:2006ic,Zhang:1994fz,Zhang:1995fu}. Tais hipóteses permitem estabelecer um limitante para a sequência $\{(\xk,\zk)\}$, o que é de vital importância para as demonstrações.

No entanto, embora as hipóteses  utilizadas nos trabalhos acima produzam uma ordem de convergência  polinomial, estas são impraticáveis do ponto da implementação, já que utilizam pontos iniciais que geram péssimo comportamento quando utilizados e ao mesmo tempo, exigem o conhecimento \emph{a priori}  de um limitante para a solução  ótima. 

Nesse trabalho, preferimos  obter uma ordem de convergência um pouco maior, embora ainda polinomial, porém com um ponto inicial cuja eficácia é bem demonstrada na prática e com uma condição que envolve o ponto inicial e uma solução ótima, condição esta foi verificada como válida, em nosso conjunto de testes. Em resumo, isso significa que a análise de convergência é feita utilizando o Algoritmo que é de fato implementado.


Como vimos na Seção \ref{subsec:initial-point}, a heurística introduzida por \textcite{Mehrotra:1992wr} é uma das mais utilizadas em diversas implementações de \acl{MPI}, por suas características de fácil utilização, bem como por seu  ótimo desempenho na prática.  Assim,  utilizaremos em nosso Algoritmo o ponto inicial de \citeauthor{Mehrotra:1992wr}, isto é, o ponto inicial $(\xzero ,\yzero,\zzero )$  dado pela equação \eqref{eq:initial-point-mehrotra}. 

 % Seja também, para este ponto inicial, a constante positiva
% \begin{equation}
% \label{eq:bdxzzero}
% 	\bdxzzero= \min_{i=1,\ldots,n}\min\{\xzero_{i},\zzero_{i}\},
% \end{equation}
% a qual será utilizada na sequência.


 Seja a constante positiva 
\begin{equation}
	\label{eq:max-norm-data}
 	\bdxzstar = \max\{\abs{A_{ij}},\abs{b_{i}},\abs{c_{j}}, \text{ para } 1\leq i\leq m \text{ e } 1\leq j \leq n  \}.
\end{equation}
$\bdxzstar$ é o maior valor absoluto de todos os dados de entrada do problema (\ref{eq:primal}-\ref{eq:dual}). Podemos supor sem perda de generalidade que $\bdxzstar \geq  1$,  bastando para isso fazer um escalamento trivial. Entretanto, na pratica usualmente são feitos escalamentos mais sofisticados, como o de \textcite{Curtis:1972cp}. Em nossa implementação, mantivemos o escalamento de \citeauthor{Curtis:1972cp}, que é  usado no PCx.

Essa constante será utilizada nas demonstrações abaixo, em particular a partir da Condição \ref{cond:xzzero-xzstar}, a qual caracteriza uma relação existente entre  o ponto inicial e uma solução ótima do \ac{PL} que estamos resolvendo. 

% \begin{cond} \label{cond:xzzero} O ponto inicial $(\xzero ,\yzero,\zzero )$ satisfaz 
% \begin{equation}
% 	\label{eq:norm-xz-zero}
% 	\norm{(\xzero,\zzero)}_{1} \leq \bdxzstar n,
% \end{equation}
% em que  $\bdxzstar>0$ calculado por \eqref{eq:max-norm-data}.
% \end{cond}

\begin{cond} \label{cond:xzzero-xzstar} Para o ponto inicial dado por \eqref{eq:initial-point-mehrotra}, com $(\xzero,\zzero)>0$,  existe uma solução ótima $(\xstar,\ystar,\zstar)$  do problema (\ref{eq:primal}-\ref{eq:dual}) que satisfaz 
\begin{equation}
	 	\label{eq:cond:xzzero-xzstar}
	 		\dfrac{2(\xzero)^T\zzero  + (\xzero)^T\zstar + (\xstar)^T\zzero}{(\xzero)^T\zzero \minxzinit} \norm{(\xzero,\zzero) - (\xstar,\zstar)} < \bdxzstar^{4},
\end{equation}
em que  $\bdxzstar>0$ é calculado por \eqref{eq:max-norm-data}. 
\end{cond}



% \begin{cond}\label{cond:x0-x*+z0-z*}  O ponto inicial $(\xzero ,\yzero,\zzero )$ dado em \eqref{eq:initial-point-mehrotra} e uma solução ótima $(\xstar,\ystar,\zstar)$ que satisfazem respectivamente as Condições \ref{cond:xzzero} e \ref{cond:xzstar}, também satisfazem as desigualdades
% \begin{subequations}\label{eq:x0-x*+z0-z*}
% \begin{gather}
% \norm{\xzero - \xstar} \leq n^2 \bdxzstar \label{eq:x0-x*} \\
% \norm{\zzero - \zstar} \leq n^2\bdxzstar \label{eq:z0-z*}
% \end{gather}
% \end{subequations}
% em que  $\bdxzstar>0$ calculado por \eqref{eq:max-norm-data}. 
% \end{cond}




%FIXME comentar a respeito dessa hipótese, depois dos resultados numéricos
% Definimos nosso ponto inicial como

% \begin{equation}
% 	\label{eq:initial-point}
% 	(\xzero ,\yzero,\zzero ) = (\bdxzstar e, 0, \bdxzstar e ).
% \end{equation}

% Temos $\xstar_{i}\leq   \bdxzstar$, bem como $\zstar_{i}\leq \bdxzstar $, para $i=1,\ldots,n$ e por isso
% \begin{equation}
% 	\label{eq:x0}
% 0\leq x^{0} - \xstar \leq \bdxzstar e \quad \text{e} \quad 0\leq \zzero  - \zstar \leq \bdxzstar e. 
% \end{equation}








% Esta análise é  baseada naquelas feitas por \textcite[cap. 6]{Wright:Primal-dual-interior-point:1997h},  \textcite{Zhang:2006ic,Zhang:1995fu}. 

O primeiro lema importante que exibiremos, mostra a existência de um limitante para $\nuk \norm{(\xk,\zk)}_{1}$. Uma demonstração similar, porém com condições para o ponto inicial e para a solução ótima diferentes da que aceitamos aqui, pode ser encontrada em~\cite[Lema 6.1]{Wright:Primal-dual-interior-point:1997h}, fonte da qual a transcrevemos com as adaptações pertinentes à nossa notação bem como à hipótese que aqui assumimos.
 % Ademais, na demonstração deste e dos outros resultados, omitiremos o índice da iteração $k$ dos vetores, para fins de clareza. 


% \subsection{Limitante para \texorpdfstring{$\nuk _k\norm{(\xk,\zk)}_{1}$}{a norma dos iterandos}}


\begin{lema}\label{lemma:boundxz1}
	Suponha que  a Condição \ref{cond:xzzero-xzstar} seja válida. Então para qualquer iterado $(\xk,\yk,\zk)$ gerado pelo Algoritmo \ref{alg:optimized-choice-of-parameters}, vale
	\begin{equation}
		\label{eq:bound-xkzk}
		\nuk \norm{(\xk,\zk)}_{1} \norm{(\xzero,\zzero) - (\xstar,\zstar)} \leq \bdxzstar^{4} n \rhoCkb ,
	\end{equation}
	em que $\nuk $ é definido em \eqref{eq:nu_k+1}.
\end{lema}

\begin{proof}
	Seja o ponto auxiliar
	\[
		(\tilde{x},\tilde{y},\tilde{z})  = \nuk (\xzero,\yzero,\zzero) + (1-\nuk )(\xstar,\ystar,\zstar) - (\xk,\yk,\zk). 
	\]
em que $(\xzero,\yzero,\zzero)$ é ponto inicial dado por \eqref{eq:initial-point-mehrotra} e $(\xstar,\ystar,\zstar)$ é  uma solução ótima, para os quais é válido \eqref{eq:cond:xzzero-xzstar}.


Note que 
\[
\begin{aligned}
A\tilde{x} & = A(\nuk \xzero+ (1-\nuk )\xstar -\xk) = \nuk (A\xzero - A\xstar) + A\xstar - A\xk   \\
& = \nuk (A\xzero - b) + (b - A\xk) = \nuk  r_{P}^{0} - r_{P}^{k}  \\
 & = r_{P}^{k} - r_{P}^{k} = 0,  
\end{aligned}
\]
e que
\[
\begin{aligned}
A^{T}\tilde{y} + \tilde{z}  & = 	A^{T}(\nuk \yzero + (1-\nuk )\ystar - \yk) + (\nuk \zzero + (1-\nuk )\zstar - \zk) \\
							&  =  \nuk  \left[(A^{T}\yzero  +\zzero)  - (A^{T}\ystar  +\zstar)  \right]+  \left[(A^{T}\ystar  +\zstar)  - (A^{T}\yk  +\zk)  \right]  \\
							& = \nuk  r_{D}^{0} - r_{D}^{k}  \\
 & = r_{D}^{k} - r_{D}^{k} = 0.   
\end{aligned}
\]


Portando, $(\tilde{x},\tilde{y},\tilde{z})$ também satisfaz \eqref{eq:Ax0-ATyz0} e então vale \eqref{eq:xTziszero}, isto é, $(\tilde{x})^{T}\tilde{z} = 0$. 

Logo temos que 
\begin{align}
	0  = \tilde{x}^{T}\tilde{z} & = (\nuk \xzero + (1-\nuk )\xstar -\xk)^{T}(\nuk \zzero + (1-\nuk )\zstar -\zk)\notag\\
	  & = \nuk ^{2}(\xzero)^T\zzero + (1-\nuk )^{2}(\xstar)^{T}\zstar + \nuk (1-\nuk )((\xzero)^{T}\zstar + (\xstar)^{T}\zzero) \notag\\
	  & \textcolor{white}{=} +(\xk)^{T}\zk - \nuk  ((\xk)^{T}\zzero + (\xzero)^{T}\zk) - (1-\nuk ) ((\xk)^{T}\zstar + (\xstar)^{T}\zk).\label{eq:boundxz1}
\end{align}

Como  $(\xk,\zk)>0$ e $(\xstar,\zstar)\geq 0$, vale $((\xk)^{T}\zstar + (\xstar)^{T}\zk) \geq 0$. Além disso, $(\xstar,\ystar,\zstar)$ é uma solução ótima, e por isso $(\xstar)^{T}\zstar = 0$. Usando essas observações e levando em conta que $\nuk \in(0,1)$,  pode-se reorganizar  a equação \eqref{eq:boundxz1} como
\begin{equation}
	\label{eq:xTzero+xzeroTz}
	  \nuk  ((\xk)^{T}\zzero + (\xzero)^{T}z) \leq 
  \nuk ^{2}(\xzero)^T\zzero  + (\xk)^{T}z+  \nuk (1-\nuk )((\xzero)^{T}\zstar + (\xstar)^{T}\zzero).
\end{equation}

Note que como  $(\xk,\zk)>0$, segue que 
\begin{multline*}
		\minxzinit\norm{(\xk,\zk)}_{1} = \minxzinit\left(\sum_{i=1}^{n}\xk_{i} + \sum_{i=1}^{n}\zk_{i} \right) \\ 
	 \leq \min_{i}(\zzero_{i})\norm{\xk}_{1} + \min_{i}(\xzero_{i})\norm{\zk}_{1}\leq
(\xk)^{T}\zzero + (\xzero)^{T}\zk,
\end{multline*}
o que implica que $
	\nuk \norm{(\xk,\zk)}_{1} \leq  \nuk ((\xk)^{T}\zzero + (\xzero)^{T}\zk)  \, \dfrac{1}{\minxzinit}.$
% \bigskip

 Comparando o primeiro termo do lado direito dessa desigualdade com  \eqref{eq:xTzero+xzeroTz} obtemos 
\[
	\nuk \norm{(\xk,\zk)}_{1}  \leq\left[ \nuk ^{2}(\xzero)^T\zzero  + (\xk)^{T}\zk+  \nuk (1-\nuk )((\xzero)^{T}\zstar + (\xstar)^{T}\zzero)\right] \, \dfrac{1}{\minxzinit}. 
\]
Agora,   $\nuk \in(0,1)$ implica que $\nu_{k}^{2}< \nu_{k}$ e que $\nuk (1-\nuk ) < \nuk $. Além disso, para qualquer $k$, $(\xk)^{T}\zk = n\rhoCkb $.  Usando esses argumentos na última desigualdade obtemos
\[
	\nuk \norm{(\xk,\zk)}_{1} 	\leq \left[ n \nuk  \dbvec{\rho_C^0} + n\rhoCkb  + \nuk ((\xzero)^{T}\zstar + (\xstar)^{T}\zzero)\right] \, \dfrac{1}{\minxzinit}.  
\]

Considerando que $(\xk,\yk,\zk)$ pertence à vizinhança $\Nset_{-\infty}(\ga,\be)$ e portanto vale  \eqref{eq:nu_k-rho0-rhok},  e considerando ainda que  $\be=1$, temos que $\nuk  \dbvec{\rho_C^0} \leq  \rhoCkb $.  


Por tudo isso,  obtemos 
\[
	\begin{aligned}
		\nuk \norm{(\xk,\zk)}_{1}  & 	\leq \left[ n\rhoCkb  + n\rhoCkb  + \left(\rhoCkb /\dbvec{\rho_C^{0}}\right)((\xzero)^{T}\zstar + (\xstar)^{T}\zzero)\right] \, \dfrac{1}{\minxzinit} \\ 
								& =  \left[ 2n\rhoCkb  +\frac{n\rhoCkb }{(\xzero)^{T}\zzero}((\xzero)^{T}\zstar + (\xstar)^{T}\zzero)\right] \, \dfrac{1}{\minxzinit} \\ 
								& = \dfrac{ 2(\xzero)^{T}\zzero  + ((\xzero)^{T}\zstar + (\xstar)^{T}\zzero)} {(\xzero)^{T}\zzero \minxzinit} \, n\rhoCkb .
		\end{aligned}
\]
 Multiplicando  ambos os lados  dessa última desiguladade por $ \norm{(\xzero,\zzero) - (\xstar,\zstar)}$ e utilizando a Equação \eqref{eq:cond:xzzero-xzstar} da Condição \ref{cond:xzzero-xzstar} finalmente obtemos

\[
	\begin{aligned}
		\nuk \norm{(\xk,\zk)}_{1}\norm{(\xzero,\zzero) - (\xstar,\zstar)}  & \leq \dfrac{ 2(\xzero)^{T}\zzero  + ((\xzero)^{T}\zstar + (\xstar)^{T}\zzero)} {(\xzero)^{T}\zzero \minxzinit} \norm{(\xzero,\zzero) - (\xstar,\zstar)} \, n\rhoCkb  \\
					& < \bdxzstar^{4}n\rhoCkb ,
		\end{aligned}
\]
como queríamos demonstrar.
\end{proof}



% \subsection{Limitantes paras normas de direções} 

A próxima proposição será utilizada nas demonstrações que seguem e é um fato conhecido e bastante utilizado em \ac{MPI}.

\begin{prop}\label{prop:norm-uv}
	Seja $D$ uma matriz diagonal não-singular de ordem $n$ e sejam $u,v\in\Real^n$, então 
	\begin{equation}
		\label{eq:prop-uvDuDv}
		\norm{uv}\leq \norm{uv}_1 \leq \norm{Du}\norm{D^{-1}v} \leq \frac{1}{2}\left(\norm{Du}^{2} + \norm{D^{-1}v}^{2}\right)
	\end{equation}
\end{prop}
\begin{proof} A primeira desigualdade é válida por conta da equivalência de normas~\cite[p.~53]{Golub:1996wp}. Quanto às demais, vejamos que 
\[
	\begin{aligned}
		\norm{uv}_1^{2} & = \left( \sum_{i=1}^{n}\abs{u_i v_i}  \right)^{2} \leq  \sum_{i=1}^{n}\abs{u_iv_i}^{2}\\
						& = \norm{uv}^{2} = (uv)^{T}(uv)  = v^{T}D^{-T}D^{T}u^{T}DD^{-1} uv\\
						& = v^{T}D^{-T}D^{T}u^{T}DuD^{-1}v = \norm{Du}^{2}\norm{D^{-1}v}^{2}.
	\end{aligned}
	\]
e logo a segunda desigualdade de \eqref{eq:prop-uvDuDv} está provada. 

Com relação a terceira desigualdade, note que  
\[
0 \leq \left(\norm{Du} - \norm{D^{-1}v}\right)^{2} = \norm{Du}^{2} - 2\norm{Du}\norm{D^{-1}v} + \norm{D^{-1}v}^{2}
\]
e portanto temos a validade de
\[
\norm{Du}\norm{D^{-1}v} \leq \frac{1}{2}\left(\norm{Du}^{1} + \norm{D^{-1}v}^{2}\right). \qedhere
\]
\end{proof}

De agora em diante, dados $(\xk,\zk)$ gerado pelo Algoritmo, definimos a matriz $\Dk$ como sendo
\[
\Dk =(\Xk)^{-1/2}(\Zk)^{1/2}.
\]

Podemos agora enunciar o seguinte lema.
\begin{lema}\label{lemma:boundDxDzaff}
Suponha válida a Condição  \ref{cond:xzzero-xzstar}. Então 

\begin{equation}
	\label{eq:normDxDzaff}
			\norm{ \dekx  \dekz  } \leq \norm{ \dekx  \dekz  }_{1}  \leq  \frac{(1 + 2\bdxzstar^{4})^{2} }{\ga} n^{2}\rhoCkb,
\end{equation}
em que $\dfrac{(1 + 2\bdxzstar^{4})^{2} }{\ga}>\num{1}$.
\end{lema}
\begin{proof}
	Seja a direção  auxiliar
	\[
		(\Dex,\Dey,\Dez)  = ( \dekx,  \deky  ,  \dekz  ) + \nuk (\xzero - \xstar,\yzero - \ystar,\zzero - \zstar), 
	\]
em que $(\xzero,\yzero,\zzero)$ é o ponto inicial dado por \eqref{eq:initial-point-mehrotra} e  $(\xstar,\ystar,\zstar)$ é uma  solução ótima, satisfazendo \eqref{eq:cond:xzzero-xzstar}.
	
	Note que 
\[
\begin{aligned}
A\Dex & = A( \dekx + \nuk (\xzero - \xstar)) \\
& =  A\dekx + \nuk (A\xzero - A\xstar)  =  A\dekx + \nuk (A\xzero - b)\\
& = -r_{P}^{k}  + \nuk  r_{P}^{0}   = -r_{P}^{k} + r_{P}^{k} = 0,  
\end{aligned}
\]
e que
\[
\begin{aligned}
A^{T}\Dey + \Dez  & = 	A^{T}(\deky + \nuk (\yzero - \ystar)) + (\dekz + \nuk (\zzero - \zstar)) \\
							& = 	(A^{T}\deky  + \dekz) + \nuk (A^{T}\yzero  + \zzero  - (A^{T}\ystar +  \zstar)) \\
							& = 	- r_{D}^{k} + \nuk (A^{T}\yzero  + \zzero  - c) \\
							& = - r_{D}^{k}  + \nuk  r_{D}^{0}   = -r_{D}^{k} + r_{D}^{k} = 0.   
\end{aligned}
\]


Portando, $(\Dex,\Dey,\Dez)$  satisfaz \eqref{eq:Ax0-ATyz0} e logo vale \eqref{eq:xTziszero}, isto é, $\Dex^{T}\Dez = 0$. Assim, 
	\begin{equation}
		\label{eq:DxDzaff1}
			 0 = \Dex^{T}\Dez = \left( \dekx +  \nuk (\xzero - \xstar)\right)^{T}\left(  \dekz   +  \nuk (\zzero - \zstar)\right).
	\end{equation}
	

	 Usando essa direção auxiliar na equação \eqref{eq:affine-scaling-system-compl}, obtemos 
	 \[
	 \Zk\left( \dekx +  \nuk (\xzero - \xstar)\right)+ \Xk \left(  \dekz   +  \nuk (\zzero - \zstar)\right) = -\xk\zk + \nuk  \Zk(\xzero - \xstar) + \nuk  \Xk(\zzero - \zstar).
	 \]
	 Multiplicando toda essa expressão por $(\Xk\Zk)^{-1/2}$, e notando que $\Dk=(\Xk\Zk)^{-1/2}\Zk$ e que $\Dik=(\Xk\Zk)^{-1/2}\Xk$, resulta em 
	\begin{multline}
		\label{eq:DxDzaff2}
		 \Dk\left( \dekx  +  \nuk (\xzero - \xstar)\right)+ \Dik \left(  \dekz   +  \nuk (\zzero - \zstar)\right) = \\ -(\xk\zk)^{1/2} + \nuk  \Dk(\xzero - \xstar) + \nuk  \Dik(\zzero - \zstar).
		\end{multline}
	 
	 Note que, como vale  \eqref{eq:DxDzaff1}, pode-se utilizar o Teorema de Pitágoras para norma-2 de vetores e logo, tomando a norma-2 ao quadrado do lado esquerdo de \eqref{eq:DxDzaff2} obtemos
	\begin{multline*}
			 	 \norm{\Dk\left( \dekx +  \nuk (\xzero - \xstar)\right)+ \Dik \left( \dekz  +  \nuk (\zzero - \zstar)\right)}^{2} =\\
	 	 	 	 	 \norm{\Dk\left( \dekx +  \nuk (\xzero - \xstar)\right)}^{2}+ \norm{\Dik \left( \dekz  +  \nuk (\zzero - \zstar)\right)}^{2}.
	\end{multline*}
	 Se  usarmos este resultado e a desigualdade triangular, após tomarmos a norma-2 ao quadrado de ambos os lados de \eqref{eq:DxDzaff2}, obtemos 
	 \begin{multline*}\label{eq:DxDzaff3}
	 \norm{\Dk\left( \dekx +  \nuk (\xzero - \xstar)\right)}^{2}+ \norm{\Dik \left( \dekz  +  \nuk (\zzero - \zstar)\right)}^{2} \leq \\ 
	 \left\{ \norm{(  \xk \zk   )^{1/2}} + \nuk  \norm{\Dk(\xzero - \xstar)} + \nuk  \norm{\Dik(\zzero - \zstar)} \right\}^{2}.
	 \end{multline*}

Isolando o primeiro termo dessa equação, obtemos
\[
\norm{\Dk\left( \dekx +  \nuk (\xzero - \xstar)\right)} \leq  
	  \norm{(  \xk \zk  )^{1/2}} + \nuk  \norm{\Dk(\xzero - \xstar)} + \nuk  \norm{\Dik(\zzero - \zstar)}.
\]
Uma aplicação direta da desigualdade triangular e a adição de um termo  $\nuk  \norm{\Dik(\zzero - \zstar)}$ extra resulta em
\begin{align}
	\norm{\Dk \dekx} & =  \norm{\Dk\left( \dekx  +  \nuk (\xzero - \xstar)  -  \nuk (\xzero - \xstar)\right)} \notag \\ 
				 & \leq	 \norm{\Dk\left( \dekx  +  \nuk (\xzero - \xstar)\right)} +  \nuk \norm{\Dk(\xzero - \xstar)} \notag \\
				 & \leq \norm{(  \xk \zk  )^{1/2}} + 2 \nuk  \norm{\Dk(\xzero - \xstar)} + 2\nuk  \norm{\Dik(\zzero - \zstar)}.\label{eq:DxDzaff4}
\end{align}

Vamos mostrar a existência de um limitante para cada termo do lado direito de \eqref{eq:DxDzaff4} de magnitude $\Oset\left(\rhoCkb ^{1/2}\right)$. Nesse caso, o mesmo se aplicará à $\norm{\Dik \dekz }$.

Para o primeiro termo, note que 
\begin{equation}
	\label{eq:DxDzaff5}
	\norm{(  \xk \zk  )^{1/2}} = \left(\sum_{i=1}^{n}\xk_i \zk_i\right)^{1/2} = ((\xk)^{T}\zk)^{1/2} = n^{1/2}\rhoCkb ^{1/2} \leq \frac{n}{\ga^{1/2}}\rhoCkb ^{1/2},
\end{equation}
já que $\ga\in(0,1)$ e $\sqrt{n}\leq n$, para todo $n$ natural.

% Para os últimos dois termos, considere primeiro que a vale a Condição \ref{cond:x0-x*+z0-z*} e portanto 
% \[
% \norm{\xzero - \xstar} \leq \bdxzstar n^2, \text{ bem como } \norm{\zzero - \zstar} \leq \bdxzstar n^2.
% \]

A norma-2 da matriz  $\Dk$ será
\[
 \norm{\Dk} = \max_{i=1,\ldots,n} \abs{\Dk_{ii}} = \norm{\Dk e}_{\infty} = \norm{(\Xk\Zk)^{-1/2}\zk}_{\infty} \leq \norm{(\Xk\Zk)^{-1/2}}\norm{\zk}_{1},
\]
e similarmente
\[
\norm{\Dik} \leq  \norm{(\Xk\Zk)^{-1/2}} \norm{\xk}_{1}.
\]

Mais que isso, como $(\xk,\yk,\zk)\in\Nset_{-\infty}(\ga,\be)$, temos que 
\begin{equation}
\label{eq:DxDzaff6}
	\norm{(\Xk\Zk)^{-1/2}} = \max_{i=1,\ldots,n}\frac{1}{(\xk_i\zk_i)^{1/2}} \leq \frac{1}{\ga^{1/2}\rhoCkb^{1/2}}.
\end{equation}

Com essas desigualdades para norma de $\Dk$ e de $\Dik$, utilizando propriedades de norma de matrizes e vetores segue que
\[
\begin{aligned}
 \nuk  \norm{\Dk(\xzero - \xstar)} + \nuk  \norm{\Dik(\zzero - \zstar)}  & \leq \nuk  \norm{\Dk}\norm{\xzero - \xstar} + \nuk  \norm{\Dik}\norm{\zzero - \zstar} \notag \\
 					& \leq \nuk \left(  \norm{\Dk} + \norm{\Dik}   \right)\norm{(\xzero,\zzero) - (\xstar,\zstar)} \\
 					& \leq \nuk  \norm{(\Xk\Zk)^{-1/2}} \left(  \norm{\xk}_{1}  +\norm{\zk}_{1}   \right)\norm{(\xzero,\zzero) - (\xstar,\zstar)} \\ 
 					& \leq  \nuk \norm{(\xk,\zk)}_{1}\norm{(\xzero,\zzero) - (\xstar,\zstar)}\norm{(\Xk\Zk)^{-1/2}}.
\end{aligned}
\]

Do Lema~\ref{lemma:boundxz1}, da Equação~\eqref{eq:DxDzaff6}  e da desigualdade acima segue que 
\begin{equation} \label{eq:DxDzaff7}
 \nuk  \norm{\Dk(\xzero - \xstar)} + \nuk  \norm{\Dik(\zzero - \zstar)}  \leq \bdxzstar^{4} n  \rhoCkb \frac{1}{\ga^{1/2}\rhoCkb ^{1/2}}  = \frac{\bdxzstar^{4}}{\ga^{1/2}}n \rhoCkb ^{1/2}.
\end{equation}

Se usarmos as equações \eqref{eq:DxDzaff5} e \eqref{eq:DxDzaff7}, comparando-as com \eqref{eq:DxDzaff4} temos que 
\[
\begin{aligned}
\norm{\Dk \dekx} & \leq \frac{n}{\ga^{1/2}}\rhoCkb ^{1/2} +  \frac{2\bdxzstar^{4}}{\ga^{1/2}}n \rhoCkb ^{1/2} \\
				& \leq \frac{1 + 2\bdxzstar^{4} }{\ga^{1/2}} n \rhoCkb ^{1/2},
\end{aligned}
\]
em que	$\dfrac{1 + 2\bdxzstar^{4} }{\ga^{1/2}} >1$,  já que  $\ga\in(0,1)$. 

Com isso, obtemos que 
	\begin{equation}\label{eq:DxDzaff8}
		\norm{\Dk  \dekx }\leq \left(\frac{1 + 2\bdxzstar^{4} }{\ga^{1/2}}\right) n\rhoCkb ^{1/2}\text{ e } \quad  \norm{\Dik  \dekz  }\leq \left(\frac{1 + 2\bdxzstar^{4} }{\ga^{1/2}}\right)n\rhoCkb ^{1/2},
		\end{equation}




Usando as desigualdades da Proposição~\ref{prop:norm-uv} e  a Equação ~\eqref{eq:DxDzaff8}, completamos a demonstração, obtendo 
\begin{align}
	\norm{ \dekx  \dekz  } \leq \norm{ \dekx  \dekz  }_{1}   & \leq \frac{1}{2}\left(\norm{\Dk \dekx}^{2} + \norm{\Dik  \dekz  }^{2}\right) \notag
  					\\ 
  					& \leq \left[\left(\frac{1 + 2\bdxzstar^{4} }{\ga^{1/2}}\right)  n\rhoCkb ^{1/2}\right]^{2}
  				= \frac{(1 + 2\bdxzstar^{4})^{2} }{\ga} n^{2}\rhoCkb . \qedhere
  				 \label{eq:normDxDzaff}
\end{align}

\end{proof}

\begin{lema}\label{lemma:boundDxDzc}
Suponha válida a Condição  \ref{cond:xzzero-xzstar}. Se  \begin{equation}
	\label{eq:sig-eta-relation}
	\nextsig > \frac{\ga(\sqrt{\ga} - \eta)}{(1+2\bdxzstar^{2})^{2}},
\end{equation} então  
	\begin{equation}\label{eq:lemma-boundDxDzcx}
		\norm{ \Dekcox  \Dekcoz  } \leq \norm{ \Dekcox  \Dekcoz  }_{1} \leq \dfrac{\left[\eta\ga + \nextsig(1+2\bdxzstar^{4})^{2}\right]^{2}}{2\ga^{3}} \: n^{4}\rhoCkb ,
	\end{equation}
	em que $\dfrac{\left[\eta\ga + \nextsig(1+2\bdxzstar^{4})^{2}\right]^{2}}{2\ga^{3}} > \num{1}$.
\end{lema}



\begin{proof}
	Note que por conta de \eqref{eq:linear-sytem-DeXDeZcorrec}, temos que $(\Dekcox,\Dekcoy,\Dekcoz)$ satisfaz \eqref{eq:Ax0-ATyz0} e logo $(\Dekcox)^{T}\Dekcoz = 0 $. 

	


	Além disso, também por causa de \eqref{eq:linear-sytem-DeXDeZcorrec}, temos que
	\[
	\Zk\Dekcox + \Xk\Dekcoz = \mu e  - \sig \dekx  \dekz .
	\]

	Multiplicando toda equação anterior por $(  \Xk \Zk  )^{-1/2}$ e  para algum $\mu$ e $\sig$ a ser escolhido, segue que 
	\[
		\Dk\Dekcox + \Dik\Dekcoz = (  \Xk \Zk  )^{-1/2}(\mu e + \sig \dekx  \dekz ).
	\] 

	Por um lado temos que 
	\[
		\begin{aligned}
		\norm{\Dk\Dekcox + \Dik\Dekcoz}^{2} & = \norm{\Dk\Dekcox}^{2} + \norm{\Dik\Dekcoz}^{2} + 2(\Dekcox)^{T}\Dekcoz  \\ &= \norm{\Dk\Dekcox}^{2} + \norm{\Dik\Dekcoz}^{2}.
		\end{aligned}
	\]

Assim, usando consistência de normas obtemos
\begin{align*}
	\norm{\Dk\Dekcox}^{2} + \norm{\Dik\Dekcoz}^{2} & = \norm{(  \Xk \Zk  )^{-1/2}(\mu e+ \sig \dekx  \dekz )}^{2} \notag\\ 
												& \leq \norm{(  \Xk \Zk  )^{-1/2}}^{2}\norm{(\mu e+ \sig \dekx  \dekz )}^{2} .	
\end{align*}


 A Equação \eqref{eq:DxDzaff6} e o fato de que  $(\xk,\yk,\zk)\in\Nset_{-\infty}(\ga,\be))$ permitem que derivemos, a partir da desigualdade acima, 
\begin{align}
	\norm{\Dk\Dekcox}^{2} + \norm{\Dik\Dekcoz}^{2} 	& \leq \min\left({\xk_i\zk_i}\right)^{-1}\left(\mu\norm{ e} +{\sig}\norm{ \dekx  \dekz }\right)^{2}\notag\\
												& \leq (\ga\rhoCkb )^{-1}\left(\mu\sqrt{n} +{\sig}\norm{ \dekx  \dekz }\right)^{2} \label{eq:DxDzc1}		
\end{align}

Para utilizar \eqref{eq:normDxDzaff}, definimos a variável local
$
t = \dfrac{(1 + 2\bdxzstar^{4})^{2} }{\ga},
$
tal que 
\[
\norm{ \dekx  \dekz  } \leq t n^{2}\rhoCkb.
\]

Agora, fixamos $\mu = \nextmu =\eta \rhoCkb $ e $\sig = \nextsig$, este último ainda a ser determinado. Notando que para todo $n$ natural vale $\sqrt{n} \leq n^{2}$, a desiguladade~\eqref{eq:DxDzc1} pode ser transformada em
\[
\begin{aligned}
	% (\ga\rhoCkb )^{-1}\left(\nextmu\sqrt{n} +\abs{\nextsig}\norm{ \dekx  \dekz }\right)^{2}  
	\norm{\Dk\Dekcox}^{2} + \norm{\Dik\Dekcoz}^{2}
							& \leq (\ga\rhoCkb )^{-1}\left(\eta\rhoCkb \sqrt{n} +{\nextsig} t n^{2}\rhoCkb \right)^{2}\\
							& \leq (\ga)^{-1}\left(\eta\sqrt{n} +{\nextsig} t n^{2}\right)^{2}\rhoCkb \\
							& \leq (\ga)^{-1}\left(\eta +{\nextsig} t \right)^{2}n^{4}\rhoCkb .
\end{aligned}
\]


Observe que $\ga\in(0,1)$ e logo $t > 1$.  Daí, e $\eta\in[0,1]$ e   se \eqref{eq:sig-eta-relation} for satisfeita, então 
\[
\nextsig > \dfrac{\sqrt{\ga} - \eta}{t}
\]
e por isso garante-se que 
$
% \label{eq:omega2}
	\dfrac{\left(\eta +{\nextsig} t \right)^{2}}{\ga} >1,
$
como queríamos.

Ao substituirmos o valor de $t$ temos 
\[
	\dfrac{\left(\eta +{\nextsig} t \right)^{2}}{\ga} = \dfrac{\left[\eta + \nextsig\dfrac{(1+2\bdxzstar^{4})^{2}}{\ga}\right]^{2}}{\ga} = \dfrac{\left[\eta\ga + \nextsig(1+2\bdxzstar^{4})^{2}\right]^{2}}{\ga^{3}},
\] 
% Wolphran Alpha code
% solve{ (1/gamma)*(eta +sigma*omega^2)^2>=1 , gamma<1, omega>=1, sigma}
%with abs(sigma)
%solve{ (1/gamma)*(eta +abs(sigma)*omega^2)^2>=1 , gamma<1, omega>=1, sigma}
%sigma>0
% solve{ (1/gamma)*(eta +(sigma)*omega^2)^2>=1 , gamma<1, omega>=1, sigma>0, sigma}
Daí, juntando tudo isso, obtemos
	\begin{equation}\label{eq:lemma-boundDxDzcx1}
		\norm{\Dk\Dekcox}^{2} + \norm{\Dik\Dekcoz}^{2} \leq \dfrac{\left[\eta\ga + \nextsig(1+2\bdxzstar^{4})^{2}\right]^{2}}{\ga^{3}} \: n^{4}\rhoCkb.
	\end{equation}

Pra finalizarmos, como consequência  das desigualdades dadas pela Proposição~\ref{prop:norm-uv} e da Equação~\eqref{eq:lemma-boundDxDzcx1} temos
\[
\begin{aligned}  				 
	\norm{ \Dekcox  \Dekcoz  } \leq \norm{ \Dekcox  \Dekcoz  }_{1}   & \leq \frac{1}{2}\left(\norm{\Dk \Dekcox}^{2} + \norm{\Dik  \Dekcoz  }^{2}\right) \notag
  					\\ 
  					& \leq \dfrac{\left[\eta\ga + \nextsig(1+2\bdxzstar^{4})^{2}\right]^{2}}{2\ga^{3}} \: n^{4}\rhoCkb,
\end{aligned}
\]
como queríamos demonstrar.
\end{proof}

\begin{lema}\label{lemma:boundDxDzaff-c}
	Suponha válida a Condição  \ref{cond:xzzero-xzstar}. Então vale 
	\begin{equation}\label{eq:lemma-boundDxDzaff-c}
		\norm{ \dekx\Dekcoz + \Dekcox  \dekz  }_{1} \leq \dfrac{2(1+2\bdxzstar^{4})\left[\eta\ga + \nextsig(1+2\bdxzstar^{4})^{2}\right]}{\ga^{2}}\: n^{3}\rhoCkb.
	\end{equation}

\end{lema}

\begin{proof}  Sejam as constantes locais
\[
t_{1} = \frac{1 + 2\bdxzstar^{4} }{\ga^{1/2}} \quad \text{ e } \quad t_{2} = \dfrac{\left[\eta\ga + \nextsig(1+2\bdxzstar^{4})^{2}\right]^{2}}{\ga^{3}}.
\]
 
	 Assim, a partir  das Equações~\ref{eq:DxDzaff8} e \eqref{eq:lemma-boundDxDzcx} e da equação \eqref{eq:prop-uvDuDv} segue que  
	\[
	\begin{aligned}	
		\norm{ \dekx \Dekcoz}_{1} & \leq \norm{\Dk \dekx }\norm{\Dik\Dekcoz}\\
							  & \leq 	t_1 n\rhoCkb ^{1/2}(t_2 n^{4}\rhoCkb )^{1/2}  \\
							  & = (t_1t_2^{1/2})n^{3}\rhoCkb .
	\end{aligned}\]			  
Similarmente, 	$\norm{\Dekcox \dekz }_{1} \leq (t_1t_2^{1/2})n^{3}\rhoCkb $. Com isso temos  que 
\[
		\norm{ \dekx \Dekcoz + \Dekcox \dekz }_{1} \leq 2(t_1t_2^{1/2})n^{3}\rhoCkb .
\]

Para finalizar, temos que  
\[
2(t_1t_2^{1/2}) = 2\frac{1 + 2\bdxzstar^{4} }{\ga^{1/2}} \cdot \dfrac{\eta\ga + \nextsig(1+2\bdxzstar^{4})^{2}}{\ga^{3/2}} = \dfrac{2(1+2\bdxzstar^{4})\left[\eta\ga + \nextsig(1+2\bdxzstar^{4})^{2}\right]}{\ga^{2}}. \qedhere
\]
\end{proof}

\section{Complexidade e  Convergência}

A fim de que o Algoritmo~\ref{alg:optimized-choice-of-parameters} esteja bem definido é necessário que exista em cada iteração $k$ uma tripla $(\al_k,\mu_k,\sig_k)$, de modo que seja possível encontrar um próximo ponto $(\nextx,\nexty,\nextz)$. Com efeito, considerando que fixamos os valores de $\mu$ como $\nextmu = \eta\rhoCkb$ e  agora que faremos $\sig$ como $\nextsig=0$, basta encontrar um  tamanho de passo ${\al_k}>0$ tal que o próximo ponto $(\nextx,\nexty,\nextz)$ satisfaça as restrições da vizinhança 
$\Nset_{-\infty}(\gamma,\beta)$ e além disso, garanta que  $0 < \theta(\al_k) <1$. É o que os próximos resultados garantem. Observe que, por conta de \eqref{eq:sig-eta-relation}, como $\nextsig =0$, garantiremos que $\eta>\sqrt{\ga}$. Isso dará o primeiro limitante para $\eta$.



\begin{lema}\label{lemma:alC_delta-1}
Seja $\nextal_{C}$ dado em \eqref{eq:al-C+al-L}. Então  
\[
\nextal_{C} \geq \delta_{1}/n^{4},
\]
em que 
\begin{equation}
	\label{eq:delta1}
	\de_{1} = \dfrac{2\eta\ga(1-\ga)}{\eta^{2} + 8\eta (1+2\bdxzstar^{4}) + 4 (1+2\bdxzstar^{4})^{2}   },
\end{equation}

é uma constante independente de $n$.
\end{lema}

\begin{proof}
 Primeiramente, considere que  assim como na Equação \eqref{eq:simplified-merit-function-al}, as escolhas de $\nextmu$ e $\nextsig$ permitem rescrever a função $g_C^i $, para $i=1,\ldots,n$, que foi dada em \eqref{eq:g-Ci_explicit}, somente dependendo de uma escolha de $\al$. De fato, temos
\[
\begin{aligned}
{g}_C^i (\al)				& = (1-\al)(\rho_C^k )_i+ \al\eta\rhoCkb + \al^2\left[(L_{0,0}^{k})_i + \eta\rhoCkb  ({L_{1,0}^{k}})_i 
				+ (\eta\rhoCkb )^2(L_{2,0}^{k})_i \right]  + \\
				& \quad -\ga\left[  (1-\al)\rhoCkb  + \al\eta\rhoCkb  + \al^2\left(\dbvec{L_{0,0}^{k}} + \eta\rhoCkb  \dbvec{L_{1,0}^{k}}.
\right)  \right]
\end{aligned}
\]
a depender somente de uma escolha de $\al$.
Sejam as constantes
\begin{equation}
\label{eq:defin-zeta-i+chi-i+xi-i}
	\begin{aligned}
\zeta_i & = (L_{0,0}^{k})_i - \ga \dbvec{L_{0,0}^{k}}, \\
\chi_i  & = \eta\rhoCkb  \left( ({L_{1,0}^{k}})_i - \ga\dbvec{L_{1,0}^{k}} \right),   \\
\xi_i	& =  (\eta\rhoCkb )^2(L_{2,0}^{k})_i . \\ 	
\end{aligned}
\end{equation}



Usando o fato de que o ponto atual pertence à vizinhança $\Nset_{-\infty}(\gamma,\beta)$, e as definições da Equação~\eqref{eq:defin-zeta-i+chi-i+xi-i} reescreve-se  $g_C^i(\al) $ como
\[
\begin{aligned}
	g_C^i (\al) & = \underbrace{(1-\al)((\rho_C^k )_i - \ga\rhoCkb )}_{\geq 0}  + (1-\ga)\eta\rhoCkb  \al+  (\zeta_i + 				\chi_i + \xi_i)\al^2  \\
				& \geq (1-\ga)\eta\rhoCkb  \al +  (\zeta_i + 				\chi_i + \xi_i)\al^2 \\ 
				& \geq (1-\ga)\eta\rhoCkb  \al -  (\abs{\zeta_i} + \abs{\chi_i} + \abs{\xi_i})\al^2 \\
				& = \al \left[	(1-\ga)\eta\rhoCkb   -  (\abs{\zeta_i} + \abs{\chi_i} + \abs{\xi_i})\al	\right] = h^i(\al),
\end{aligned}
\]
em que $h^i$ é uma quadrática côncava em função de $\al$ com uma raiz nula e uma positiva. 


Vamos agora obter limitantes para $\abs{\zeta_i}$, $ \abs{\chi_i}$ e para  $\abs{\xi_i}$.

Considere primeiramente que nas substituições que seguem, as definições dos vetores $L_{\ell,j}^{k}$ dadas em~\eqref{eq:defining-Lij} fazem com que sejma válidas $\abs{({L_{\ell,j}^{k}})_{i}} \leq \norm{L_{\ell,j}^{k}}_{1}$ e $\abs{\dbvec{L_{\ell,j}^{k}}} \leq \dfrac{1}{n}\norm{L_{\ell,j}^{k}}_{1}$.

Mais que isso, já que $\ga/n < 1$, obtemos
\begin{equation}\label{eq:absLij}
 	\abs{({L_{\ell,j}^{k}})_{i} - \ga\dbvec{L_{\ell,j}^{k}}} \leq  	\abs{({L_{\ell,j}^{k}})_{i}} + \abs{\ga\dbvec{L_{\ell,j}^{k}}} \leq  \norm{L_{\ell,j}^{k}}_{1}+ \frac{\ga}{n}\norm{L_{\ell,j}^{k}}_{1} \leq 2 \norm{L_{\ell,j}^{k}}_{1}.
 \end{equation} 

Para o limitante de $\abs{\zeta_{i}}$ note que por conta de \eqref{eq:defin-zeta-i+chi-i+xi-i} e também pela mostrado em  \eqref{eq:absLij} segue que 
\begin{equation}
\abs{\zeta_i}    \leq 2\norm{L_{0,0}^{k}}_1 \label{eq:bound-zeta-i} \leq 2\norm{ \dekx  \dekz }_1.   % \leq 2\omega_1^{2} n^{2}\rhoCkb . 
\end{equation}

Para $\abs{\chi_{i}}$, considere que   $\sig = \nextsig=0$, que vale as definições dadas em \eqref{eq:Corrector-spllited} e como  $\mu=\nextmu = \eta\rhoCkb$ fixado, temos que $\Decow = \nextmu \Dew^{\mu} + \nextsig
\Dew^{\sig} = \eta\rhoCkb \Dew^\mu $ e por isso 
	\[
		 \eta\rhoCkb (\Dex^\mu)^{k} = \Dekcox     \quad \text{ e } \quad    \eta\rhoCkb (\Dez^\mu)^{k} = \Dekcoz .
	\]

	Assim, $ L_{1,0}^{k} = \dekx(\Dez^\mu)^{k} +
			\dekz(\Dex^\mu)^{k} = \dekx\Dekcoz +
			\dekz\Dekcox $ e novamente, usando  \eqref{eq:absLij} segue que
\begin{equation}\label{eq:bound-chi-i}
	\abs{\chi_i } = \abs{\eta\rhoCkb  \left( ({L_{1,0}^{k}})_i - \ga\dbvec{L_{1,0}^{k}} \right)}  \leq 2 \norm{ \dekx \Dekcoz + \Dekcox \dekz }_1. %  \leq \omega_{3}n^{3}\rhoCkb .
\end{equation}

Finalmente para o limitante de $\abs{\xi_{i}}$, e utilizarmos  a equação \eqref{eq:Corrector-spllited}, novamente com as escolhas $\nextmu $ e $\nextsig$ acima, temos
\[
	\Dekcox\Dekcoz = (\eta\rhoCkb \Dex^\mu)(\eta\rhoCkb \Dez^\mu) = (\eta\rhoCkb )^2(L_{2,0}^{k}).
\]
Portanto segue que
\begin{equation}\label{eq:bound-xi-i}
	\abs{\xi_i}	 =  \abs{(\eta\rhoCkb )^2(L_{2,0}^{k})_i}  = \abs{(\Dekcox\Dekcoz)_i} \leq \norm{\Dekcox\Dekcoz}_1.% \leq \tfrac{1}{2} \omega_2 n^{4}\rhoCkb .
\end{equation}
	


Agora note que, para $\al>0$ e para todo $i=1,\ldots,n$, se $h^i(\al)\geq0$ então $g_C^i(\al)\geq 0$. 

Com efeito, a única raiz positiva de $h^i$ é dada por
\begin{equation}
	\label{eq:al-Ci-final}
	\al_{C}^i = \dfrac{(1-\ga)\eta\rhoCkb }{\abs{\zeta_i} + \abs{\chi_i} + \abs{\xi_i}}
\end{equation}
e $h^i(\al)\geq 0$ sempre que $\al\in[0,\al_{C}^i].$ 



Utilizando \eqref{eq:bound-zeta-i}, \eqref{eq:bound-chi-i} e \eqref{eq:bound-xi-i}  é possível encontrar um limitante para o denominador de \eqref{eq:al-Ci-final}. Primeiro considere que podemos escrever a  
desigualdade
\[
\abs{\zeta_i} + \abs{\chi_i} + \abs{\xi_i} \leq 2\norm{ \dekx  \dekz }_1 + 2 \norm{ \dekx \Dekcoz + \Dekcox \dekz }_1 + \norm{\Dekcox\Dekcoz}_1.
\]



Os Lemas \ref{lemma:boundDxDzaff},   \ref{lemma:boundDxDzc} e \ref{lemma:boundDxDzaff-c}  fazem com que a desigualdade acima transforme-se em 
\begin{multline*}
\abs{\zeta_i} + \abs{\chi_i} + \abs{\xi_i}  \leq \\  \frac{2(1 + 2\bdxzstar^{4})^{2} }{\ga} n^{2}\rhoCkb + 
												\dfrac{4(1+2\bdxzstar^{4})\left[\eta\ga + \nextsig(1+2\bdxzstar^{4})^{2}\right]}{\ga^{2}}\: n^{3}\rhoCkb + 	 \dfrac{\left[\eta\ga + \nextsig(1+2\bdxzstar^{4})^{2}\right]^{2}}{2\ga^{3}} \: n^{4}\rhoCkb.
\end{multline*}

Como $\nextsig = 0$ e $n^{2}\leq n^{3}\leq  n^{4}$ e definindo $t = (1 + 2\bdxzstar^{4})$, temos que 

	\begin{align}
	\abs{\zeta_i} + \abs{\chi_i} + \abs{\xi_i} & \leq \left[ \frac{2(1 + 2\bdxzstar^{4})^{2} }{\ga} + 												\dfrac{4\eta(1+2\bdxzstar^{4})}{\ga} +	 \dfrac{\eta^{2}}{2\ga} \right] n^{4}\rhoCkb \notag \\
										& =	\dfrac{1}{\ga}\left[ 2t^{2} + 4\eta t + \eta^{2}/2 \right] n^{4}\rhoCkb
										\label{eq:zeta+chi+xi}
	\end{align}

Como $\nextal^{i}_{C}$, dada em \eqref{eq:al-C+al-L}, é o maior número em $(0,1]$ tal que $g_{C}^{i}(\al)\geq 0$, para $\al\leq\nextal^{i}_{C}$, e além disso para todo $\al$ vale $g_{C}^{i}(\al) \geq h^{i}(\al)$, claramente $\nextal^{i}_{C} \geq  \al_{C}^i$ para todo $i=1,\ldots,n$.


Por conta disso, e a partir  de \eqref{eq:al-Ci-final} e de \eqref{eq:zeta+chi+xi} temos que 
\[
\begin{aligned}
\nextal_{C}^i \geq \al_{C}^{i} & \geq \dfrac{(1-\ga)\eta\rhoCkb}{\dfrac{1}{\ga}\left( 2t^{2} + 4\eta t + \eta^{2}/2 \right)\rhoCkb n^{4} } \\			 
							& = \dfrac{\ga(1-\ga)\eta}{ 2t^{2} + 4\eta t + \eta^{2}/2 } \:\dfrac{1}{n^{4}} = \dfrac{\de_{1}}{n^{4}},
\end{aligned}
\]
em que a substituição de $t$ na penúltima igualdade acima, nos dá a Equação~\eqref{eq:delta1}.

 O lema fica provado, considerando que para algum $j\in\{1,\ldots,n\}$, $ \al_{C}^{j}=\nextal_{C} $.
 \end{proof}






\begin{lema}\label{lemma:alL_delta-2}
Seja $\nextal_{L}$ dado em \eqref{eq:al-C+al-L}. Então 
\[
\nextal_{L} \geq \delta_{2}/n^{2},
\]em que 
\begin{equation}
	\label{eq:delta2}
	\delta_{2} = \dfrac{\ga\eta } {(1 + 2\bdxzstar^{4})^{2}  + 2(1+2\bdxzstar^{4})\eta}
\end{equation}
é uma constante independente de $n$.
\end{lema}


\begin{proof}

Usando as mesmas substituições de $\nextmu$ e $\nextsig$, a função $g_L$ dada em \eqref{eq:g-L_explicit} torna-se uma função que depende apenas de $\al$, nos seguintes termos 
\[
g_L(\al) =     (1-\al)\left(\rhoCkb  -  \be_L \nuk    \right) +  \al\eta\rhoCkb  + 
   \al^2\left( \dbvec{L_{0,0}^{k}} + \eta\rhoCkb   \,\dbvec{L_{1,0}^{k}}   \right ) ,
	\]
Usando  o fato de que o ponto atual pertence à  vizinhança segue que 
 \[
\begin{aligned}
{g}_L(\al) & =     (1-\al)\underbrace{\left(\rhoCkb  -  \be_L \nuk    \right)}_{\geq 0} +  \al\eta\rhoCkb  + 
   \al^2\left( \dbvec{L_{0,0}^{k}} + \eta\rhoCkb  \, \dbvec{L_{1,0}^{k}}   \right ) \\
   & \geq  \al\left[\eta\rhoCkb  - 
   \al \left(\abs{\dbvec{L_{0,0}^{k}}} + \abs{\eta\rhoCkb\,  \dbvec{L_{1,0}^{k}}}\right)   \right ].
\end{aligned}
 \]
Note que  $\nextal_L\in(0,1]$ -- definido em \eqref{eq:al-C+al-L} -- é o maior número tal que  $g_L(\al)\geq 0$, para  $\al\in[0,\nextal_L]$. Por conta da última inequação acima, temos que 
\begin{equation}
	\label{eq:next-al-ineq}
\nextal_L \geq \frac{\eta\rhoCkb  }{\abs{\dbvec{L_{0,0}^{k}}} + \abs{\eta\rhoCkb \,  \dbvec{L_{1,0}^{k}}}}.
\end{equation}

Novamente, como na demonstração do Lema \ref{lemma:alC_delta-1}, a seguir fazemos $\sig = \nextsig=0$ e  $\mu=\nextmu = \eta\rhoCkb $ e usamos as definições dos vetores $L_{i,j}^{k}$ dadas em~\eqref{eq:defining-Lij} e que 
\[\abs{\dbvec{L_{i,j}^{k}}} = \frac{1}{n}\norm{L_{i,j}^{k}}_{1},\] 

e logo  vem que  
\begin{equation}
\abs{\dbvec{L_{0,0}^{k}}}  = \frac{1}{n}\norm{L_{0,0}^{k}}_{1}  \leq \dfrac{1}{n} \norm{ \dekx  \dekz }_1 .  \label{eq:bound-zeta}
\end{equation}

Além disso,  $\eta\rhoCkb (\Dex^\mu)^{k} = \Dekcox $  e $  \eta\rhoCkb (\Dez^\mu)^{k} = \Dekcoz$ .


Assim,  segue que

	\begin{align}
	\abs{\eta\rhoCkb \,  \dbvec{L_{1,0}^{k}}} & = \dfrac{1}{n}\norm{\eta\rhoCkb L_{1,0}^{k}}_{1}  \notag \\
	& =  \dfrac{1}{n} \norm{ \dekx \Dekcoz + \Dekcox \dekz }_1.\label{eq:bound-chi}
	\end{align}


Os Lema~\ref{lemma:boundDxDzaff-c} e  \ref{lemma:boundDxDzaff} em conjunto com  as Equações \eqref{eq:next-al-ineq}, \eqref{eq:bound-zeta} e \eqref{eq:bound-chi} derivam 
\[
\begin{aligned}
\nextal_L  & \geq \frac{\eta\rhoCkb  } {\dfrac{1}{n} \left(\norm{ \dekx  \dekz }_1 +  \norm{ \dekx \Decoz  \Decox \dekz }_1 \right) } \\
		   & \geq \dfrac{\eta\rhoCkb  } {\dfrac{1}{n} \left(\dfrac{(1 + 2\bdxzstar^{4})^{2} }{\ga} n^{2}\rhoCkb + \dfrac{2(1+2\bdxzstar^{4})\left[\eta\ga + \nextsig(1+2\bdxzstar^{4})^{2}\right]}{\ga^{2}}\: n^{3}\rhoCkb  \right) } \\
		   & = \left( \dfrac{\ga\eta } {(1 + 2\bdxzstar^{4})^{2}  + 2(1+2\bdxzstar^{4})\eta}\right) \dfrac{1}{n^{2}} = \frac{\delta_{2}}{n^{2}}, 
\end{aligned}
\]
em que $\de_{2}$ é exatamente o dado na Equação \eqref{eq:delta2}
\end{proof}
 
Agora podemos enunciar e demonstrar  Teorema que mostra que a sequência $\left\{ \varphi_{k}\right\}$ gerada pelo nosso Algoritmo tem taxa de convergência Q-linear. 

\begin{teo}[Taxa de Convergência do Algoritmo  \ref{alg:optimized-choice-of-parameters}]\label{lemma:next-phi-delta-n4}
A sequência $\{\varphi_{k}\}$ gerada pelo Algoritmo~\ref{alg:optimized-choice-of-parameters} é tal que
\begin{equation}
		\label{eq:varphi-delta-n4}
				\varphi_{k+1}\leq \left(1 - \frac{\hat{\delta}}{n^{4}}\right)\varphi_{k},
	\end{equation}
	para todo $k$, em que $0<\nextdel<1$ e $\nextdel$ independente de $n$.
\end{teo}


\begin{proof} Por conta da Equação \eqref{eq:nex-al}, e dos Lemas \ref{lemma:alC_delta-1} e \ref{lemma:alL_delta-2}, podemos escolher, sem perda de generalidade, $\nextal = \delta_{1}/n^{4}$, com $\de_{1}$ dado em \eqref{eq:delta1}. 

Precisamos  primeiro mostrar que $\theta(\nextal)= \Oset(1/n^{4})$. Para isso, considere que pelas definições dadas em dadas em~\eqref{eq:defining-Lij} em conjunto com  as Equações  \eqref{eq:bound-zeta} e \eqref{eq:bound-chi} e ainda  os Lema~\ref{lemma:boundDxDzaff-c} e \ref{lemma:boundDxDzaff} deriva-se 
\[
- \dbvec{L_{0,0}^{k}} \geq - \dfrac{1}{n} \norm{ \dekx  \dekz }_1 \geq - \dfrac{(1 + 2\bdxzstar^{4})^{2} }{\ga} n\rhoCkb
\]
e 
\[
- \eta\rhoCkb  \dbvec{L_{1,0}^{k}} \geq - \dfrac{1}{n} \norm{ \dekx \Dekcoz + \Dekcox \dekz }_1 \geq - \dfrac{2(1+2\bdxzstar^{4})\eta }{\ga}\: n^{2}\rhoCkb.
\]



Seja $t = (1+2\bdxzstar^{4})$ e $t_1 = \dfrac{t}{\ga}$. 
Daí, considerando que $\dfrac{\rhoCkb }{\nuk \dbvec{\rho_L}_0 + \rhoCkb }\leq 1$ temos que


\[
	\begin{aligned}
		\theta(\nextal)% & =  \dfrac{1}{\nuk \dbvec{\rho_L}_0 + \rhoCkb }\left[ \nuk \dbvec{\rho_L}_0\nextal + (1- \eta)\rhoCkb \nextal - \nextal^{2}\left(\dbvec{L_{0,0}^{k}} + \eta\rhoCkb  \dbvec{L_{1,0}^{k}} \right) \right] \\
						& = \dfrac{1}{\nuk \dbvec{\rho_L}_0 + \rhoCkb }\left[ (\nuk \dbvec{\rho_L}_0 + \rhoCkb )\nextal -  \eta\rhoCkb \nextal - \nextal^{2}\left(\dbvec{L_{0,0}^{k}} + \eta\rhoCkb \, \dbvec{L_{1,0}^{k}} \right) \right] \\
						& \geq \dfrac{1}{\nuk \dbvec{\rho_L}_0 + \rhoCkb }\left[ (\nuk \dbvec{\rho_L}_0 + \rhoCkb )\nextal -  \eta\rhoCkb \nextal - \nextal^{2}t_{1}\left(\ga t_{1}^{2} n\rhoCkb  + 2\eta t_1 n^{2}\rhoCkb  \right) \right]\\
						%
						& \geq \nextal - \dfrac{\rhoCkb }{\nuk \dbvec{\rho_L}_0 + \rhoCkb } \left[   \eta\nextal + \nextal^{2} t_{1}\left(\ga t_1 n + 2\eta  n^{2}  \right) \right]\\
						& \geq \nextal \left[ 1 -  \eta - \nextal t_{1}\left(\ga t_1 n + 2\eta  n^{2}  \right) \right] \\
						& \geq \frac{\delta_{1}}{n^{4}} \left[ 1 -  \eta - \frac{\delta_{1}}{n^{4}}t_{1}\left(\ga t_1 n + 2\eta  n^{2}  \right) \right] \\
						& \geq 	 \left[ (1 -  \eta)\delta_{1} - \delta_{1}^{2}t_{1}\left(\ga t_1  + 2\eta    \right) \right] \frac{1}{n^{4}}	
						 = \frac{\nextdel}{n^{4}},		
		\end{aligned}
	\]
	com 	\begin{equation}
		\label{eq:nextdelta}
		\nextdel = 
	(1 -  \eta)\delta_{1} - \delta_{1}^{2}t_{1}\left(\ga t_{1}  + 2\eta    \right) = (1 -  \eta)\delta_{1} - \dfrac{\delta_{1}^{2}}{\ga}\left((1+2\bdxzstar^{4})^{2}  + 2\eta(1+2\bdxzstar^{4})    \right).
	\end{equation} 
	
	 A demonstração será finalizada ao verificarmos que $0<\nextdel<1$.

Agora, utilizando a definição de $\de_1$ dada em \eqref{eq:delta1} e substituindo na última igualdade, encontramos o valor de $\nextdel$ a depender de $\ga$ e $\eta$,  ou seja, 
	\begin{equation}
		\label{eq:nextdel-full}
		\nextdel = (2\ga\eta)\frac{\left(4 t^2 +(8t - 6t^2   -2t^2\ga) \eta - ( 1 - 4t    - 4t   \ga) ) \eta^2 - \eta^3\right)}{(4t^2 + 8t\eta + \eta^{2})^{2}}.
	\end{equation}

	Para o primeiro termo de \eqref{eq:nextdel-full}, temos que $0 < (2\ga\eta) <1$.

	Quanto ao segundo termo, note que o denominador é  sempre maior que o numerador, para qualquer  valor de $\ga$ e $\eta$. Basta mostrar que  o numerador deste segundo termo acima é positivo. Com efeito, tal numerador é o polinômio 
	\[
		p(\eta,\ga) =  4 t^2 + ( 8t - 6t^2 + 2t^2\ga) \eta + (1 - 4t - 4t   \ga) ) \eta^2 - \eta^3. 
	\]

	Considerando que $t\geq3$, pois $\bdxzstar\geq1$ e $\sqrt{\ga}<\eta<1$, para $0 < \ga \leq 1/10$, segue que
	\[p(\sqrt{1/10},\ga) >0 \text{ e  } p(1,\ga) <0.\]
	Sob essas condições, escolhido $\ga$,  $p$ um é polinômio de grau 3 em $\eta$. Pelo Teorema do Valor Intermediário de Bolzano~\cite[Teorema 5.3.7]{Bartle:2011tr},  existe pelo menos uma  raiz  de $p$ no intervalo $(\sqrt{1/10},1)$. 

	Seja $\eta_{1}$ a menor dessas raízes. Nesse caso, por continuidade de $p$, para qualquer $\eta  < \eta_{1}$ e $\ga$ escolhido como acima, temos que  $p(\eta,\ga) >0$. 

	Com isso, concluímos que,  para $0 < \ga \leq 1/10$ e  $\sqrt{\ga}<\eta<1$, vale  $0<\nextdel<1$  sempre que $\eta < \eta_{1} < 1$, o que completa a demonstração.
% \textcolor{red}{Como terminar? $\nextdel$ precisa ser menor que 1? Maior que 0? O que mais? Já sei que $\eta > \sqrt{\ga}$, para essa escolha de $\mu$ e $\sigma$.}
\end{proof}








Finalmente podemos enunciar e provar o Teorema de complexidade. 


\begin{teo}[Complexidade do Algoritmo \ref{alg:optimized-choice-of-parameters}]
	\label{teo:alg-convergence-varphi} Seja $0 < \varepsilon <1$ dado. Suponha que a sequência $\{\varphi_{k}\}$ gerada pelo Algoritmo~\ref{alg:optimized-choice-of-parameters} é  tal que 
	para o ponto inicial $(\xzero,\yzero,\zzero)$ dado em \eqref{eq:initial-point-mehrotra} seja válido	
	\begin{equation}
	\label{eq:varphi0-eps-kappa}
		\varphi_{0}\leq \dfrac{1}{\varepsilon^{\kappa}},
	\end{equation} 
	com  $\kappa$ uma constante positiva. Então  existe um índice \[K =  \Oset\left(n^{4}{\ln\frac{1}{\varepsilon}}\right),\] tal que 
	 $\varphi_{k}\leq \varepsilon \text{ para todo } k \geq K$.
	 
\end{teo}

\begin{proof} Para mostrarmos a complexidade polinomial do algoritmo, aplicamos o logaritmo natural em ambos os lados da inequação \eqref{eq:varphi-delta-n4} dada no Lema \ref{lemma:next-phi-delta-n4}, obtendo
	\[
	\ln\varphi_{k+1}\leq \ln \left(1 - \frac{\hat{\delta}}{n^{4}}\right) + \ln\varphi_{k},
	\]
Usando um argumento indutivo e utilizando \eqref{eq:varphi0-eps-kappa} segue que
\[
	\begin{aligned}
		\ln\varphi_{k} & \leq k \ln\left(1 - \frac{\hat{\delta}}{n^{4}}\right) + \ln \varphi_{0} \\
					& \leq k \ln\left(1 - \frac{\hat{\delta}}{n^{4}}\right) + \kappa\ln \frac{1}{\varepsilon}. 
	\end{aligned}
\] 

Conforme \textcite[Lema 4.1, p.~68]{Wright:Primal-dual-interior-point:1997h}, temos que $\ln(1+r) \leq r$, sempre que $r>-1$. Assim
\[
	\ln\varphi_{k}\leq k \left(- \frac{\hat{\delta}}{n^{4}}\right) + \kappa\ln \frac{1}{\varepsilon}.
\] 

Para que o critério de convergência $\varphi_{k}\leq\varepsilon$ seja satisfeito, devemos garantir que 
\[
	k \left(- \frac{\hat{\delta}}{n^{4}}\right) + \kappa\ln \frac{1}{\varepsilon} \leq \ln\varepsilon.
\] 
De fato, tal inequação é válida para 
\[
	k \geq \dfrac{n^{4}}{\hat{\delta}}(1+\kappa)\ln\frac{1}{\varepsilon},
\]
o que termina a demonstração.
\end{proof}






O Teorema \ref{teo:alg-convergence-varphi} implica que para um $k$ suficientemente grande, o valor de $\varphi$ será tão pequeno quanto se deseja. No entanto, tal resultado ainda não implica que algum critério de parada usual de Métodos de Pontos Interiores é satisfeito. Porém é possível garantir que o Critério de Parada dado na Equação~\eqref{eq:termination-criteria-pcx}, seja satisfeito para uma escolha particular de $\varepsilon$. Tal garantia, dada pelo Corolário a seguir, permite concluir que a sequência $\left\{\norm{(r_{P}^{k},r_{D}^{k})}\right\}$ tem taxa de convergência R-linear~\cite{Ortega:2000vd}.

\begin{corol}
Suponha que escolha-se  $\tol = \num{e-8}$  e $\varepsilon$   tal que 
\begin{equation}
	\label{eq:choosing-eps}
		\varepsilon < \min\left\{  \frac{\tol(1+\norm{b})}{m+n}, \frac{\tol(1+\norm{c})}{m+n},\frac{\tol}{n}\right\}.
\end{equation}
Se o Algoritmo \ref{alg:optimized-choice-of-parameters} converge com tal $\eps$, então o critério de parada dado na Equação~\eqref{eq:termination-criteria-pcx} é satisfeito.
\end{corol}		

\begin{proof}
	 Pelas Definições \ref{def:residual-vector} e \ref{def:merit-function}, vale
	\begin{equation}
		\label{eq:varphi-rhoP-rhoD}
				\varphi_{k} =  \frac{\norm{\rho^{k}_L}_1}{m+n} + 
\frac{(x^{k})^Tz^{k}}{n}  = \frac{\norm{H_{P}(Ax^{k} - b)}_1}{m+n} +\frac{\norm{H_{D}(A^{T}y^{k} + z^{k}- c)}_1 }{m+n} + 
\frac{(x^{k})^Tz^{k}}{n}.
	\end{equation}

Além disso, por equivalência de normas e pela definção de $H_{P}$ e $H_{D}$ dadas na Equação \eqref{eq:defining_matrices_H}, temos que $\norm{Ax^{k} - b} \leq \norm{Ax^{k} - b}_{1} = \norm{H_{P}(Ax^{k} - b)}_{1}$ e que $\norm{H_{D}(A^{T}y^{k} + z^{k}- c)} \leq \norm{A^{T}y^{k} + z^{k}- c}_1 = \norm{H_{D}(A^{T}y^{k} + z^{k}- c)}_1$.

Ademais, se  o Algoritmo \ref{alg:optimized-choice-of-parameters} converge, existe $k$ suficientemente grande tal que $\varphi_{k}<\eps$. Assim, cada um dos termos da última parte de \eqref{eq:varphi-rhoP-rhoD} é menor que $\varepsilon$.


Daí, pela Equação \eqref{eq:choosing-eps}, segue que 
\[
\dfrac{\norm{Ax^{k} - b}}{1 + \norm{b}} \leq  \frac{\norm{H_{P}(Ax^{k} - b)}_1  }{1 + \norm{b}} < \frac{\eps (m+n)}{1 + \norm{b}} <\frac{\tol(1+\norm{b})}{m+n} \frac{m+n}{1 + \norm{b}} = \tol,
\]
e
\[
\dfrac{\norm{A^{T}y^{k} + z^{k}- c}}{1 + \norm{c}} \leq  \frac{\norm{H_{D}(A^{T}y^{k} + z^{k}- c)}_{1}  }{1 + \norm{c}} < \frac{\eps (m+n)}{1 + \norm{c}} <\frac{\tol(1+\norm{c})}{m+n} \frac{m+n}{1 + \norm{c}} = \tol.
\]
Além disso, como $1+ |c^{T}x^{k}| \geq 1$, temos que 
\[
\dfrac{(x^{k})^{T}z^{k}}{1+ |c^{T}x^{k}|} <   \frac{n\cdot  \eps}{1+ |c^{T}x^{k}|} \leq n \cdot \eps < n \frac{\tol}{n} = \tol. \qedhere
\]
 \end{proof}

%   \begin{algorithm}[htb]
%  \onehalfspacing
%  \caption{Método de Escolha Adiada de Parâmetros Simplificado.}
%  \label{alg:optimized-choice-of-parameters} 
% \begin{algorithmic}[1]
% \Procedure{ResolveLP}{$A,b,c$}
% \State $(\xzero ,\yzero,\zzero ) \gets$ \Call{PontoInicial}{$A,b,c$}.
% \Comment{Assegure que  $(\xzero ,\zzero )>0$ e que $\eta\in(0,1)$}
% 	\For {$k=1,2,\ldots$}
% 		\State Encontre		$( \dekx,  \deky  ,  \dekz  )$ resolvendo
% 				\begin{equation}
% 				\label{eq:predictor-linear-matrix-simplified}
% 				\bbm A & 0 & 0 \\
% 				0 & A^T & I\\
% 				Z^k & 0 & X^k \ebm
% 				\bbm \dekx  \\ \deky  \\ \dekz
% 				\ebm = 
% 				\bbm -r_P^k  \\ -r_D^k \\ -r_C^k
% 				\ebm.
% 			\end{equation}
% 		\State 	Faça $\nextmu=\eta{(x^k)^Tz^k}/{n}$ e  $\nextsig=0$, e resolva 
% 		% \[((\Decox)^{k},(\Decoy)^{k},(\Decoz)^{k}) = \bar{\mu}((\Dex^{\mu})^{k},(\Dey^{\mu})^{k},(\Dez^{\mu})^{k})\]
% 		% resolvendo
% 			\begin{equation}
% 				\label{eq:corrector-linear-matrix-simplified}
% 				\bbm A & 0 & 0 \\
% 				0 & A^T & I\\
% 				\Zk & 0 & \Xk \ebm
% 				\bbm (\Decox)^{k} \\ (\Decoy)^{k} \\ (\Decoz)^{k}
% 				\ebm = 
% 				\bbm 0  \\ 0 \\  \nextmu e %- \bar{\sig}\deX \dekz 
% 				\ebm.
% 			\end{equation}
% 		\State Encontre $\al^*$ resolvendo o subproblema de
% 		otimização global 	\eqref{eq:pop-subproblem}.		
% 		\State Escolha $\al_k = \min\{\al^*,\tilde{\al}_k\}$ com $\tilde{\al}_k$ dado por $\eqref{eq:ratio-test}$ e faça
% 		\[
% 		\begin{aligned}	
% 		& x^{k+1} = x^{k} + \al_k( \dekx + (\Decox)^{k} )
% 		\\
% 		& y^{k+1} = y^{k} + \al_k(  \deky   + (\Decoy)^{k} )
% 		\\
% 		& z^{k+1} = z^{k} + \al_k(  \dekz   + (\Decoz)^{k} )
% 		 \end{aligned}. 
% 		\]		
% 	\EndFor
% \EndProcedure
% \end{algorithmic}
% \end{algorithm}



A melhor complexidade para métodos de pontos interiores preditores-corretores do tipo Mehrotra com ponto inicial infactível é dado por \textcite{Zhang:1996it}, com ordem de iterações $\Oset(n^{\num{1.5}})$ e taxa de convergência Q-subquadrática. Nossa análise demonstrou que temos uma ordem de iterações um pouco maior, $\Oset(n^{\num{4}})$, porém polinomial, e convergência Q-linear. 

Dois comentários são importantes. Quanto tanto sabemos, os algoritmos 

%COmplexidade depende da função de mérito. gap relativo vs gap. 

% EXPLICAR COMO É QUE O WRIGHT IMPLEMENTA O QOOP. QUE A DEMONSTRAÇÃO DO GONDZIO É FEITA PRA PONTO FACTÍVEL.


No presente capítulo, estabelecemos os resultados de complexidade polinomial e convergência  do Método de Escolha Otimizada de Parâmetros, em relação à função de mérito que estamos usando. Isso foi feito através das ferramentas de demonstração utilizadas em \acl{MPI}. Além disso, garantimos que é possível escolher um $\eps>0$, tal que se a função de mérito em uma dada iteração é limitada superiormente por esse $\eps$, o critério de parada  usado em várias implementações também é satisfeito. Neste sentido, do ponto de vista teórico,  garantimos que o \ac{MPI} de Escolha Otimizada de Parâmetros (EOP) converge assintoticamente para pontos com factibilidade e otimalidade. No capítulo que segue, mostramos alguns detalhes dos experimentos numéricos feitos com este método.


